{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# imports\n",
    "from glob import glob\n",
    "import json\n",
    "import numpy as np\n",
    "from plyfile import PlyData, PlyElement\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyvista as pv\n",
    "import sys\n",
    "import os.path as osp\n",
    "from matplotlib import pyplot as plt\n",
    "sys.path.append(\"./segmentation/cutpursuit/pcd-prox-split/grid-graph/python\")\n",
    "from grid_graph import edge_list_to_forward_star # type: ignore\n",
    "from segmentation.cutpursuit.python.wrappers.cp_d0_dist import cp_d0_dist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Pre-process the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_map = {\n",
    "    'Red':'red',\n",
    "    'Green':'green',\n",
    "    'Blue':'blue',\n",
    "    'riegl_reflectance':'intensity',\n",
    "}\n",
    "\n",
    "# discard\n",
    "'riegl_amplitude', \n",
    "'riegl_deviation', \n",
    "'riegl_targetIndex',\n",
    "'riegl_targetCount', \n",
    "'scan_id', \n",
    "\n",
    "# labels\n",
    "label_names = [\n",
    "    'labels_0', \n",
    "    'labels_1', \n",
    "    'labels_2',\n",
    "    'labels_3'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG flattening labels\n",
      "2023-08-28_FW_EingangBauing_pointcloud.ply\n",
      "2024-03-22_FW_Koenigshuegel_pointcloud.ply\n",
      "2024-04-05_FW_Westbahnhof_01_pointcloud.ply\n",
      "2024-04-05_FW_Westbahnhof_02_pointcloud.ply\n",
      "2024-04-05_FW_Westbahnhof_03_pointcloud.ply\n",
      "2024-04-05_FW_Westbahnhof_04_pointcloud.ply\n",
      "2024-04-05_FW_Westbahnhof_05_pointcloud.ply\n",
      "2024-05-10_FW_RWTH_Zentrum_01_pointcloud.ply\n",
      "2024-07-31_FW_Bruecke_Koenigstr_pointcloud.ply\n",
      "2024-07-31_FW_Bruecke_Turmstr_pointcloud.ply\n",
      "2024-08-02_FW_Bruecke_A44_VerlautenheidenerStr_pointcloud.ply\n",
      "2024-08-02_FW_Bruecke_Deltourserb_pointcloud.ply\n",
      "2024-08-02_FW_Bruecke_Kasinostrasse_pointcloud.ply\n",
      "2024-08-02_FW_Bruecke_RotheErde_pointcloud.ply\n",
      "2024-08-02_FW_Bruecke_Rottstrasse_pointcloud.ply\n"
     ]
    }
   ],
   "source": [
    "\n",
    "raw_path = \"/media/hristo/sharedData1/00_Projects/24-10-26_SPP_PCS/02_Datasets/FWF_Subsampled/0.01\"\n",
    "osp.exists(raw_path)\n",
    "\n",
    "with open(osp.join(raw_path,'class_dict.json'),'r') as f:\n",
    "    schema = json.load(f)\n",
    "\n",
    "print(f\"DEBUG flattening labels\")\n",
    "all_labels = []\n",
    "for pcd_fp in glob(osp.join(raw_path,'*','labeled','*.ply')):\n",
    "    print(osp.basename(pcd_fp))\n",
    "    pcd = pd.DataFrame(PlyData.read(pcd_fp).elements[0].data)\n",
    "    labels = pcd[label_names].to_numpy(dtype=np.int64)\n",
    "    all_labels.append(labels)\n",
    "\n",
    "    # pos = pcd[['x','y','z']].to_numpy()\n",
    "    # pos -= pos.mean(axis=0)\n",
    "    # feats = pcd[feat_map.keys()].rename(columns=feat_map)\n",
    "    \n",
    "\n",
    "\n",
    "all_labels = np.concatenate(all_labels,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "out_dir = \"./data/FWF_flat\"\n",
    "\n",
    "\n",
    "# create flat inds\n",
    "uq, inv = np.unique(all_labels,return_inverse=True,axis=0)\n",
    "\n",
    "# create flat schema\n",
    "new_schema = dict()\n",
    "for i,l in enumerate(uq):\n",
    "    new_name = []\n",
    "    for ln, li in zip(label_names, l):\n",
    "        sch_inv = {v:k for k,v in schema[ln].items()}\n",
    "        new_name.append(sch_inv[li])\n",
    "        \n",
    "    new_name = '-'.join(new_name)\n",
    "    new_schema[i] = new_name\n",
    "    \n",
    "\n",
    "with open(osp.join(out_dir,'schema.yaml'),'w') as f:\n",
    "    yaml.dump(new_schema, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from typing import Tuple\n",
    "def build_csr(edge_idx: torch.Tensor, num_nodes: int) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:\n",
    "    sys.path.append(\"./segmentation/cutpursuit/pcd-prox-split/grid-graph/python\")\n",
    "    from grid_graph import edge_list_to_forward_star\n",
    "    indptr, indices, reidx = edge_list_to_forward_star(\n",
    "        num_nodes, edge_idx.T.contiguous().cpu().numpy()\n",
    "    )\n",
    "    return indptr.astype(np.uint32), indices.astype(np.uint32), reidx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "ignore_names = [\n",
    "    # \"2023-08-28_FW_EingangBauing_pointcloud\",\n",
    "    # \"2024-03-22_FW_Koenigshuegel_pointcloud\",\n",
    "    # \"2024-04-05_FW_Westbahnhof_01_pointcloud\",\n",
    "    # \"2024-04-05_FW_Westbahnhof_02_pointcloud\",\n",
    "    # \"2024-04-05_FW_Westbahnhof_03_pointcloud\",\n",
    "    # \"2024-04-05_FW_Westbahnhof_04_pointcloud\",\n",
    "    # \"2024-04-05_FW_Westbahnhof_05_pointcloud\",\n",
    "    # \"2024-05-10_FW_RWTH_Zentrum_01_pointcloud\",\n",
    "    # \"2024-07-31_FW_Bruecke_Koenigstr_pointcloud\",\n",
    "    # \"2024-07-31_FW_Bruecke_Turmstr_pointcloud\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Area 001: 2023-08-28_FW_EingangBauing_pointcloud.ply: 49it [01:35,  1.95s/it]\n",
      "Area 002: 2024-03-22_FW_Koenigshuegel_pointcloud.ply: 15it [00:14,  1.04it/s]\n",
      "Area 003: 2024-04-05_FW_Westbahnhof_01_pointcloud.ply: 3it [00:19,  6.42s/it]\n",
      "Area 004: 2024-04-05_FW_Westbahnhof_02_pointcloud.ply: 2it [00:07,  3.76s/it]\n",
      "Area 005: 2024-04-05_FW_Westbahnhof_03_pointcloud.ply: 6it [00:17,  2.92s/it]\n",
      "Area 006: 2024-04-05_FW_Westbahnhof_04_pointcloud.ply: 5it [00:24,  4.87s/it]\n",
      "Area 007: 2024-04-05_FW_Westbahnhof_05_pointcloud.ply: 1it [00:06,  6.98s/it]\n",
      "Area 008: 2024-05-10_FW_RWTH_Zentrum_01_pointcloud.ply: 15it [00:46,  3.12s/it]\n",
      "Area 009: 2024-07-31_FW_Bruecke_Koenigstr_pointcloud.ply: 37it [03:08,  5.10s/it]\n",
      "Area 010: 2024-07-31_FW_Bruecke_Turmstr_pointcloud.ply: 36it [01:43,  2.89s/it]\n",
      "Area 011: 2024-08-02_FW_Bruecke_A44_VerlautenheidenerStr_pointcloud.ply: 37it [02:19,  3.78s/it]\n",
      "Area 012: 2024-08-02_FW_Bruecke_Deltourserb_pointcloud.ply: 26it [00:51,  1.98s/it]\n",
      "Area 013: 2024-08-02_FW_Bruecke_Kasinostrasse_pointcloud.ply: 35it [02:21,  4.04s/it]\n",
      "Area 014: 2024-08-02_FW_Bruecke_RotheErde_pointcloud.ply: 41it [02:55,  4.29s/it]\n",
      "Area 015: 2024-08-02_FW_Bruecke_Rottstrasse_pointcloud.ply: 50it [01:19,  1.59s/it]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import os\n",
    "from utils.pointcloud import compute_geometric_feats\n",
    "from torch_geometric.nn import knn_graph\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "\n",
    "### CONFIG\n",
    "config_cp_args = dict(\n",
    "    regularization = 0.8,\n",
    "    spatial_weight = 100,\n",
    "    cutoff = 15,\n",
    "    cp_dif_tol =  1e-2,\n",
    "    cp_it_max = 20,\n",
    "    split_damp_ratio = 0.7\n",
    ")\n",
    "config_chunk_size = np.array([10,10])\n",
    "config_device = 'cuda'\n",
    "\n",
    "###\n",
    "\n",
    "all_pcds = dict()\n",
    "start   = 0\n",
    "end     = 0\n",
    "\n",
    "out_dir_processed = osp.join(out_dir,f'{config_chunk_size[0]:.1f}X{config_chunk_size[1]:.1f}')\n",
    "os.makedirs(out_dir_processed, exist_ok=True)\n",
    "out_dir_processed_ply = osp.join(out_dir_processed,'ply')\n",
    "out_dir_processed_graph = osp.join(out_dir_processed,'graph')\n",
    "os.makedirs(out_dir_processed_ply, exist_ok=True)\n",
    "os.makedirs(out_dir_processed_graph, exist_ok=True)\n",
    "\n",
    "\n",
    "# second iteration with flat inds\n",
    "for area_i, pcd_fp in enumerate(glob(osp.join(raw_path,'*','labeled','*.ply'))):\n",
    "    \n",
    "    pcd_name = osp.basename(pcd_fp).replace('.ply','')\n",
    "    if pcd_name in ignore_names:\n",
    "        continue\n",
    "\n",
    "    pcd = pd.DataFrame(PlyData.read(pcd_fp).elements[0].data)\n",
    "    pos = pcd[['x','y','z']].to_numpy()\n",
    "    pos -= pos.min(axis=0)\n",
    "    feats = pcd[feat_map.keys()].rename(columns=feat_map)\n",
    "    \n",
    "    # slice labels\n",
    "    end += pos.shape[0]\n",
    "    labels = inv[start:end]\n",
    "    assert labels.shape[0] == pos.shape[0]\n",
    "    start = end\n",
    "\n",
    "    # extract chunk inds\n",
    "    c_coord = pos[:,:2] // config_chunk_size\n",
    "    chunk_uq_coords, chunk_idx = np.unique(c_coord, return_inverse=True, axis=0)\n",
    "\n",
    "    # slice pcd in chunks\n",
    "    for chunk_i, chunk_uq_coord in tqdm(enumerate(chunk_uq_coords),desc=f\"Area {area_i+1:03}: {osp.basename(pcd_fp)}\"):\n",
    "        pos_c       = pos[chunk_idx == chunk_i].astype(np.float32)\n",
    "        feats_c     = feats[chunk_idx == chunk_i].to_numpy().astype(np.float32)\n",
    "        labels_c    = labels[chunk_idx == chunk_i].astype(np.int32)\n",
    "        \n",
    "        # center chunk\n",
    "        pos_c[:,:2] -= config_chunk_size / 2\n",
    "        pos_c[:,2]  -= pos_c[:,2].min()\n",
    "\n",
    "        device = config_device if pos_c.shape[0] < 500_000 else 'cpu'\n",
    "        if pos_c.shape[0] < 3000:\n",
    "            continue\n",
    "\n",
    "\n",
    "        pcd_c = pd.DataFrame(np.concat([pos_c, feats_c, labels_c[:,None]], axis=1), columns=['x','y','z'] + list(feat_map.values()) + ['labels'])\n",
    "        out_name = f\"Area_{area_i+1:02}_X{int(chunk_uq_coord[0]):03}-Y{int(chunk_uq_coord[1]):03}\"\n",
    "        PlyData([PlyElement.describe(pcd_c.to_records(index=False),'vertex')]).write(osp.join(out_dir_processed_ply, f\"{out_name}.ply\"))\n",
    "        \n",
    "        # gather and extract graph building features\n",
    "        edge_index = knn_graph(torch.as_tensor(pos_c).to(device=device), k=10)\n",
    "        gfeats_c = compute_geometric_feats(torch.as_tensor(pos_c).to(device=device), edge_index, feat_names=[\n",
    "            'normals', \n",
    "            'verticality', \n",
    "            'linearity', \n",
    "            'planarity', \n",
    "            'scattering', \n",
    "        ])      \n",
    "        pfeats_c = np.concatenate([\n",
    "            feats_c,\n",
    "            gfeats_c['normals'].cpu().numpy(), \n",
    "            gfeats_c['verticality'][:,None].cpu().numpy(), \n",
    "            gfeats_c['linearity'][:,None].cpu().numpy(), \n",
    "            gfeats_c['planarity'][:,None].cpu().numpy(), \n",
    "            gfeats_c['scattering'][:,None].cpu().numpy(), \n",
    "            pos_c[:,2][:,None],\n",
    "            \n",
    "        ],axis=1)\n",
    "\n",
    "        # normalize\n",
    "        pfeats_c -= pfeats_c.mean(axis=0)\n",
    "        pfeats_c /= (np.std(pfeats_c, axis=0) + 1e-6)\n",
    "\n",
    "        # build graph\n",
    "        Df = pos_c.shape[1] + pfeats_c.shape[1]\n",
    "        Xf = np.asfortranarray(np.concatenate([pos_c - pos_c.mean(0), pfeats_c], axis=1).T, dtype=np.float64)\n",
    "        src, tgt, _ = build_csr(edge_index, pos_c.shape[0])\n",
    "\n",
    "\n",
    "        \n",
    "        ew = np.ones_like(tgt, np.float64) * config_cp_args.get('regularization', 0.1)\n",
    "        vw = np.ones(pos_c.shape[0], np.float64)\n",
    "        cw = np.ones(Df, np.float64)\n",
    "        cw[:pos_c.shape[1]] *= config_cp_args.get('spatial_weight', 10.0)\n",
    "        sup, _, graph = cp_d0_dist(\n",
    "            Df, Xf, src, tgt,\n",
    "            edge_weights=ew, vert_weights=vw, coor_weights=cw,\n",
    "            min_comp_weight=config_cp_args.get('cutoff',5),\n",
    "            cp_dif_tol=config_cp_args.get('cp_dif_tol',1e-2),\n",
    "            cp_it_max=config_cp_args.get('cp_it_max',10), # type:ignore\n",
    "            split_damp_ratio=config_cp_args.get('split_damp_ratio',0.7),\n",
    "            verbose=False, max_num_threads=0,\n",
    "            balance_parallel_split=True,\n",
    "            compute_List=False, compute_Graph=True, compute_Time=False\n",
    "        )\n",
    "\n",
    "        g_out = dict(\n",
    "            superpoint_idx = sup,\n",
    "            edges_forwardstar = graph,\n",
    "            point_feats = pfeats_c\n",
    "        )\n",
    "        with open(osp.join(out_dir_processed_graph,f\"{out_name}.pkl\"),\"wb\") as f:\n",
    "            pickle.dump(g_out, f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import colorsys\n",
    "# import pyvista as pv\n",
    "\n",
    "# def index_to_color(indices):\n",
    "#     \"\"\"\n",
    "#     Map integer indices to vibrant RGB colors.\n",
    "\n",
    "#     Parameters\n",
    "#     ----------\n",
    "#     indices : int or array-like of ints\n",
    "#         Input index or indices. Can be a scalar or an iterable of ints.\n",
    "\n",
    "#     Returns\n",
    "#     -------\n",
    "#     colors : ndarray of shape (N, 3)\n",
    "#         RGB colors in the range [0, 1], where N is the number of indices.\n",
    "#     \"\"\"\n",
    "#     # Ensure array of ints\n",
    "#     indices = np.atleast_1d(np.array(indices, dtype=int).flatten())\n",
    "    \n",
    "#     # Use the golden ratio conjugate to spread hues evenly\n",
    "#     phi = 0.618033988749895\n",
    "#     hues = (indices * phi) % 1.0\n",
    "    \n",
    "#     # Vibrancy settings\n",
    "#     s, v = 0.9, 0.95  # saturation and value\n",
    "    \n",
    "#     # Convert each hue to RGB\n",
    "#     colors = np.array([colorsys.hsv_to_rgb(h, s, v) for h in hues], dtype=float)\n",
    "#     return colors\n",
    "\n",
    "\n",
    "# plotter = pv.Plotter(notebook=True)\n",
    "# colors = index_to_color(sup)\n",
    "# poly = pv.PolyData(pos_c)\n",
    "# poly['RGB'] = colors\n",
    "# plotter.add_mesh(poly, scalars='RGB', rgb=True)\n",
    "# plotter.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3dapp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
